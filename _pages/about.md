---
permalink: /
title: "About"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% include base_path %}

Iâ€™m a third-year Ph.D. student in Computer Science at the <span style="color:#990000;">University of Southern California (USC)</span>. My main research interests are deep learning theory, natural language processing, and the interpretability of AI systems. I'm (co-)advised by [Prof. Vatsal Sharan](https://vatsalsharan.github.io) of [USC Theory Group](https://viterbi-web.usc.edu/~cstheory/) and [Prof. Robin Jia](https://robinjia.github.io) of [Allegro Lab](https://allegro-lab.github.io) within [USC NLP Group](https://nlp.usc.edu), and I'm working closely with [Prof. Mahdi Soltanolkotabi](https://viterbi-web.usc.edu/~soltanol/index.html) and [Prof. Shang-Hua Teng](https://viterbi-web.usc.edu/~shanghua/).


## Research
You can find a full picture of my research in the [publications](/publications/) page or the [Google scholar](https://scholar.google.com/citations?user=fsbgfqEAAAAJ&hl=en) page. They belong to the following categories.
<h3 style="text-decoration:underline">Algorithmic Perspectives on Large Language Models</h3>
How to think about LLMs and transformers architectures from a theoretical and algorithmic perspective? 
- How transformer implements its capabilitie of in-context learning? Is it really doing gradient descent in-context? [(NeurIPS 2024)](https://arxiv.org/abs/2310.17086)
- How pretrained LLMs compute simple arithmetic tasks? Memorization or Mechanisms? [(NeurIPS 2024)](https://arxiv.org/abs/2406.03445)
- Can we use classical decision theory to guide LLMs to make decisions under uncertainty? [(ICLR 2025)](DeLLMa.github.io)

<h3 style="text-decoration:underline">Synthetic Data and Multimodal Learning</h3>
How can we evaluate Multimodal LLMs/VLMs in a robust way? How could we improve them with synthetic data?
- Are Multimodal LLMs sensitive to the input modality of the same problem? [(COLM 2024)](https://arxiv.org/abs/2404.01266)
- Improving Text-to-Image models with VLM's feeback. [(NAACL 2025)](https://arxiv.org/abs/2311.17946)
- Evaluating Multimodal LLMs' hallucination rates by training an token-level reward model (TLDR). Improving Multimodal LLMs with TLDR at both training and inference time. [(ICLR 2025)](https://arxiv.org/abs/2410.04734)

## Education
- University of Southern California, 2022 - Present
  - Ph.D. in Computer Science
- University of Chicago, 2016 - 2022
  - M.S. in Statistics
  - B.S. *with Honors* in Mathematics, Computer Science, and Statistics
