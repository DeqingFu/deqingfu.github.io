---
permalink: /
title: "About"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% include base_path %}

<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Orbitron:wght@400..900&display=swap" rel="stylesheet">

<style>
  body {
    font-family: "Orbitron", sans-serif;
  }
  .arial {
    font-family: Arial, sans-serif !important;
  }
</style>

<button id="fontToggle">Switch to Arial</button>

<div style="line-height: 1.6; color: #333; display: flex;">
  <div style="width: 60%; padding-right: 20px;">
    <p>Iâ€™m a third-year Ph.D. student in Computer Science at the <span style="color:#990000;">University of Southern California (USC)</span>. My main research interests are deep learning theory, natural language processing, and the interpretability of AI systems. I'm (co-)advised by <a href="https://vatsalsharan.github.io" style="color: #990000;">Prof. Vatsal Sharan</a> of <a href="https://viterbi-web.usc.edu/~cstheory/" style="color: #990000;">USC Theory Group</a> and <a href="https://robinjia.github.io" style="color: #990000;">Prof. Robin Jia</a> of <a href="https://allegro-lab.github.io" style="color: #990000;">Allegro Lab</a> within <a href="https://nlp.usc.edu" style="color: #990000;">USC NLP Group</a>, and I'm working closely with <a href="https://viterbi-web.usc.edu/~soltanol/index.html" style="color: #990000;">Prof. Mahdi Soltanolkotabi</a> and <a href="https://viterbi-web.usc.edu/~shanghua/" style="color: #990000;">Prof. Shang-Hua Teng</a>.</p>

    <h2 style="color: #990000; border-bottom: 2px solid #990000; padding-bottom: 5px;">News</h2>
    <div>
      <!-- Add your news items here -->
      <div style="margin-bottom: 10px;">
        <h4 style="margin: 0; color: #990000;">Feb 12, gave a talk at Duke NLP Seminar</h4>
        <p style="margin: 0; font-size: 14px; color: #555;">February 12, 2025</p>
        <p style="margin: 0;">Gave a talk at Duke NLP Seminar.</p>
      </div>
      <div style="margin-bottom: 10px;">
        <h4 style="margin: 0; color: #990000;">Jan 22, three papers accepted to ICLR 2025. DeLLMa got spotlight.</h4>
        <p style="margin: 0; font-size: 14px; color: #555;">January 22, 2025</p>
        <p style="margin: 0;">Three papers (<a href="https://arxiv.org/abs/2410.04734" style="color: #990000;">TLDR</a>, <a href="https://arxiv.org/abs/2403.06925" style="color: #990000;">Sensitivity</a>, and <a href="https://arxiv.org/abs/2402.02392" style="color: #990000;">DeLLMa</a>) accepted to ICLR 2025. <a href="https://arxiv.org/abs/2402.02392" style="color: #990000;">DeLLMa</a> got spotlight.</p>
      </div>
    </div>

    <h2 style="color: #990000; border-bottom: 2px solid #990000; padding-bottom: 5px;">Research</h2>
    <p>You can find a full picture of my research on the <a href="/publications/" style="color: #990000;">publications</a> page or my <a href="https://scholar.google.com/citations?user=fsbgfqEAAAAJ&hl=en" style="color: #990000;">Google Scholar</a> page. They belong to the following categories:</p>

    <h3 style="color: #990000; text-decoration: underline;">Algorithmic Perspectives on Large Language Models</h3>
    <p><em>How to think about LLMs and transformers architectures from a theoretical and algorithmic perspective?</em></p>
    <ul>
      <li>How transformer implements its capability of in-context learning? Is it really doing gradient descent in-context? <a href="https://arxiv.org/abs/2310.17086" style="color: #990000;">(NeurIPS 2024)</a></li>
      <li>How pretrained LLMs compute simple arithmetic tasks? Memorization or Mechanisms? <a href="https://arxiv.org/abs/2406.03445" style="color: #990000;">(NeurIPS 2024)</a></li>
      <li>Can we use classical decision theory to guide LLMs to make decisions under uncertainty? <a href="https://DeLLMa.github.io" style="color: #990000;">(ICLR 2025)</a></li>
    </ul>

    <h3 style="color: #990000; text-decoration: underline;">Synthetic Data and Multimodal Learning</h3>
    <p><em>How can we evaluate Multimodal LLMs/VLMs in a robust way? How could we improve them with synthetic data?</em></p>
    <ul>
      <li>Are Multimodal LLMs sensitive to the input modality of the same problem? <a href="https://arxiv.org/abs/2404.01266" style="color: #990000;">(COLM 2024)</a></li>
      <li>Improving Text-to-Image models with VLM's feedback. <a href="https://arxiv.org/abs/2311.17946" style="color: #990000;">(NAACL 2025)</a></li>
      <li>Evaluating Multimodal LLMs' hallucination rates by training a token-level reward model (TLDR). Improving Multimodal LLMs with TLDR at both training and inference time. <a href="https://arxiv.org/abs/2410.04734" style="color: #990000;">(ICLR 2025)</a></li>
    </ul>

    <h2 style="color: #990000; border-bottom: 2px solid #990000; padding-bottom: 5px;">Education</h2>
    <ul>
      <li>University of Southern California, 2022 - Present
        <ul>
          <li>Ph.D. in Computer Science</li>
        </ul>
      </li>
      <li>University of Chicago, 2016 - 2022
        <ul>
          <li>M.S. in Statistics</li>
          <li>B.S. <em>with Honors</em> in Mathematics, Computer Science, and Statistics</li>
        </ul>
      </li>
    </ul>
  </div>

  <div style="width: 30%;">
    <h2 style="color: #990000; border-bottom: 2px solid #990000; padding-bottom: 5px;">Connect</h2>
    <a class="twitter-timeline" href="https://twitter.com/DeqingFu?ref_src=twsrc%5Etfw">Tweets by DeqingFu</a> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
  </div>
</div>

<script>
  const fontToggle = document.getElementById('fontToggle');
  const body = document.querySelector('body');

  fontToggle.addEventListener('click', function() {
    if (body.classList.contains('arial')) {
      body.classList.remove('arial');
      fontToggle.textContent = 'Switch to Arial';
    } else {
      body.classList.add('arial');
      fontToggle.textContent = 'Switch to Orbitron';
    }
  });
</script>
